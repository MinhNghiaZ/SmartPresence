import { useRef, useEffect, useState, useCallback, useImperativeHandle, forwardRef } from 'react';
import { useNotifications } from '../../context/NotificationContext';
import { faceRecognizeService } from '../../Services/FaceRecognizeService/FaceRecognizeService.ts';
import { CameraPolyfill } from '../../Services/CameraPolyfill';
import CameraRequirements from '../CameraRequirements'; // Fixed case
import type { FaceRecognitionResult } from '../../Services/FaceRecognizeService/FaceRecognizeService.ts';
import './FaceRecognition.css';

interface FaceRecognitionProps {
  onRecognitionResult?: (results: FaceRecognitionResult[]) => void;
  onError?: (error: string) => void;
  autoRecognize?: boolean; // T·ª± ƒë·ªông nh·∫≠n d·∫°ng li√™n t·ª•c
  recognizeInterval?: number; // Kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn nh·∫≠n d·∫°ng (ms)
  autoStartCamera?: boolean; // T·ª± ƒë·ªông kh·ªüi ƒë·ªông camera khi mount
}

export interface FaceRecognitionRef {
  stopCamera: () => void;
  startCamera: () => void;
}

// Mobile detection utility
const isMobile = () => {
  return /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
};

// Get camera constraints optimized for mobile with fallbacks
const getCameraConstraints = (fallback = false): MediaStreamConstraints => {
  const mobile = isMobile();
  
  if (fallback) {
    // Minimal constraints for maximum compatibility
    return {
      video: true,
      audio: false
    };
  }
  
  if (mobile) {
    return {
      video: {
        width: { ideal: 480, max: 640 },
        height: { ideal: 360, max: 480 },
        facingMode: 'user', // Front camera for mobile
        frameRate: { ideal: 15, max: 24 } // Lower framerate for mobile performance
      },
      audio: false
    };
  } else {
    return {
      video: {
        width: { ideal: 640 },
        height: { ideal: 480 },
        frameRate: { ideal: 30 }
      },
      audio: false
    };
  }
};

// Check if camera is available with comprehensive diagnostics using polyfill
const checkCameraSupport = async (): Promise<{
  supported: boolean;
  details: string;
  cameras: MediaDeviceInfo[];
  diagnostics: any;
}> => {
  const result = {
    supported: false,
    details: '',
    cameras: [] as MediaDeviceInfo[],
    diagnostics: null as any
  };

  try {
    // Get comprehensive diagnostics
    const diagnostics = CameraPolyfill.getDiagnostics();
    result.diagnostics = diagnostics;

    // Check environment requirements
    if (!diagnostics.isHTTPS && !diagnostics.isLocalhost) {
      result.details = `HTTPS Required: Camera c·∫ßn HTTPS. Hi·ªán t·∫°i: ${diagnostics.protocol}//${location.hostname}`;
      return result;
    }

    // Check API availability
    if (!diagnostics.modernAPI && !diagnostics.legacyAPI) {
      result.details = 'Browser kh√¥ng h·ªó tr·ª£ camera API. Vui l√≤ng c·∫≠p nh·∫≠t browser.';
      return result;
    }

    // Try to enumerate devices (if modern API available)
    if (diagnostics.modernAPI && navigator.mediaDevices.enumerateDevices) {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        result.cameras = devices.filter(device => device.kind === 'videoinput');
        
        if (result.cameras.length === 0) {
          result.details = 'Kh√¥ng t√¨m th·∫•y camera n√†o tr√™n thi·∫øt b·ªã';
          return result;
        }
      } catch (enumError) {
        result.details = 'Kh√¥ng th·ªÉ li·ªát k√™ devices: ' + (enumError as Error).message;
        return result;
      }
    }

    // Test actual camera access using polyfill
    const cameraTest = await CameraPolyfill.testCamera();
    
    if (cameraTest.success) {
      result.supported = true;
      result.details = cameraTest.details;
      
      // Clean up test stream
      if (cameraTest.stream) {
        cameraTest.stream.getTracks().forEach(track => track.stop());
      }
    } else {
      result.details = cameraTest.details;
    }

    return result;

  } catch (error) {
    result.details = 'L·ªói ki·ªÉm tra camera: ' + (error as Error).message;
    return result;
  }
};

const FaceRecognition = forwardRef<FaceRecognitionRef, FaceRecognitionProps>(({
  onRecognitionResult,
  onError,
  autoRecognize = false,
  recognizeInterval = 1000,
  autoStartCamera = false
}, ref) => {
  const notify = useNotifications();
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const overlayCanvasRef = useRef<HTMLCanvasElement>(null);
  const intervalRef = useRef<number | null>(null);
  // Prevent duplicate side-effects (React StrictMode double-invoke in dev) & error spam
  const autoStartTimeoutRef = useRef<number | null>(null);
  const isStartingCameraRef = useRef(false);
  const lastErrorRef = useRef<{ msg: string; ts: number } | null>(null);

  // Centralized error emitter with de-duplication (2s window)
  const emitError = useCallback((rawMsg: string) => {
    const msg = rawMsg.trim();
    const now = Date.now();
    const last = lastErrorRef.current;
    if (last && last.msg === msg && now - last.ts < 2000) {
      // Skip duplicate
      return;
    }
    lastErrorRef.current = { msg, ts: now };
    setError(msg);
    onError?.(msg);
  }, [onError]);
  
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isCameraActive, setIsCameraActive] = useState(false);
  const [isRecognizing, setIsRecognizing] = useState(false);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string>('');
  const [lastResults, setLastResults] = useState<FaceRecognitionResult[]>([]);
  const [showRequirements, setShowRequirements] = useState(false);
  const [isFaceAligned, setIsFaceAligned] = useState(false); // Khu√¥n m·∫∑t c√≥ n·∫±m trong v√πng guide kh√¥ng

  // Kh·ªüi t·∫°o models khi component mount
  useEffect(() => {
    initializeService();
    return () => {
      stopCamera();
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      if (autoStartTimeoutRef.current) {
        clearTimeout(autoStartTimeoutRef.current);
        autoStartTimeoutRef.current = null;
      }
    };
  }, []);

  // Expose methods to parent component
  useImperativeHandle(ref, () => ({
    stopCamera,
    startCamera
  }));

  // Auto recognize effect
  useEffect(() => {
    if (autoRecognize && isCameraActive && isModelLoaded) {
      startAutoRecognition();
    } else {
      stopAutoRecognition();
    }
    
    return () => stopAutoRecognition();
  }, [autoRecognize, isCameraActive, isModelLoaded, recognizeInterval]);

  const initializeService = async () => {
    try {
      setLoading(true);
      setError('');
      
      if (!faceRecognizeService.isReady()) {
        await faceRecognizeService.initializeModels();
      }
      
      faceRecognizeService.loadFacesFromStorage();
      setIsModelLoaded(true);
      // console.log('Face recognition service ƒë√£ s·∫µn s√†ng');
      
      // T·ª± ƒë·ªông kh·ªüi ƒë·ªông camera n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
      if (autoStartCamera) {
        if (autoStartTimeoutRef.current) {
          clearTimeout(autoStartTimeoutRef.current);
        }
        autoStartTimeoutRef.current = window.setTimeout(() => {
          startCamera();
        }, 500);
      }
    } catch (err) {
      // Error propagation contract:
      //  - This component sets local error state & calls onError
      //  - Parent (e.g. HomeScreen) is solely responsible for user-facing notifications
      //  - Do NOT push notifications here to avoid duplicate toasts
  const errorMsg = 'Kh√¥ng th·ªÉ kh·ªüi t·∫°o face recognition service: ' + (err as Error).message;
  emitError(errorMsg);
  console.error(err);
    } finally {
      setLoading(false);
    }
  };

  const startCamera = async () => {
    if (isStartingCameraRef.current || isCameraActive) {
      return; // Guard against re-entry / duplicate start
    }
    isStartingCameraRef.current = true;
    try {
      setError('');
      
      // Comprehensive camera check first
      // console.log('üìπ Starting comprehensive camera check...');
      const cameraCheck = await checkCameraSupport();
      
      if (!cameraCheck.supported) {
        // Check if it's an HTTPS issue
        if (cameraCheck.details.includes('HTTPS') || cameraCheck.details.includes('https')) {
          setShowRequirements(true);
          return;
        }
        throw new Error(cameraCheck.details);
      }
      
      // console.log('üìπ Camera check passed:', cameraCheck.details);
      // console.log('üìπ Available cameras:', cameraCheck.cameras.length);

      let stream: MediaStream | null = null;
      
      // Try multiple camera access strategies using polyfill
      const strategies = [
        // Strategy 1: Mobile optimized with polyfill
        () => CameraPolyfill.getUserMedia(getCameraConstraints(false)),
        // Strategy 2: Basic fallback with polyfill
        () => CameraPolyfill.getUserMedia(getCameraConstraints(true)),
        // Strategy 3: Minimal constraints with polyfill
        () => CameraPolyfill.getUserMedia({ video: true, audio: false }),
        // Strategy 4: No constraints with polyfill
        () => CameraPolyfill.getUserMedia({ video: {} })
      ];
      
      for (let i = 0; i < strategies.length; i++) {
        try {
          // console.log(`üìπ Trying camera strategy ${i + 1}/${strategies.length}`);
          stream = await strategies[i]();
          // console.log(`üìπ Strategy ${i + 1} succeeded!`);
          break;
        } catch (strategyError) {
          console.warn(`üìπ Strategy ${i + 1} failed:`, strategyError);
          if (i === strategies.length - 1) {
            throw strategyError; // Last strategy failed, throw error
          }
        }
      }
      
      if (!stream) {
        throw new Error('T·∫•t c·∫£ camera strategies ƒë√£ th·∫•t b·∫°i');
      }
      
      // Validate stream
      const videoTracks = stream.getVideoTracks();
      if (videoTracks.length === 0) {
        stream.getTracks().forEach(track => track.stop());
        throw new Error('Stream kh√¥ng ch·ª©a video track');
      }
      
      // const videoTrack = videoTracks[0]; // For future debugging
      // console.log('üìπ Video track info:', {
      //   label: videoTrack.label,
      //   kind: videoTrack.kind,
      //   readyState: videoTrack.readyState,
      //   settings: videoTrack.getSettings?.()
      // });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.playsInline = true;
        videoRef.current.muted = true;
        videoRef.current.autoplay = true;
        
        // Wait for video to be ready
        await new Promise<void>((resolve, reject) => {
          const video = videoRef.current!;
          const timeout = setTimeout(() => {
            reject(new Error('Video load timeout - Camera c√≥ th·ªÉ b·ªã kh√≥a ho·∫∑c ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng'));
          }, 20000); // Even longer timeout
          
          const onLoadedMetadata = () => {
            clearTimeout(timeout);
            cleanup();
            
            // console.log('üìπ Video metadata loaded:', {
            //   videoWidth: video.videoWidth,
            //   videoHeight: video.videoHeight,
            //   duration: video.duration,
            //   readyState: video.readyState
            // });
            
            // Force play
            video.play()
              .then(() => {
                setupCanvas();
                setIsCameraActive(true);
                // console.log('üìπ Camera started successfully');
                resolve();
              })
              .catch((playError) => {
                console.error('Video play failed:', playError);
                reject(new Error('Kh√¥ng th·ªÉ ph√°t video t·ª´ camera: ' + playError.message));
              });
          };
          
          const onError = (event: Event) => {
            cleanup();
            console.error('Video element error:', event);
            reject(new Error('L·ªói video element'));
          };
          
          const cleanup = () => {
            clearTimeout(timeout);
            video.removeEventListener('loadedmetadata', onLoadedMetadata);
            video.removeEventListener('error', onError);
          };
          
          video.addEventListener('loadedmetadata', onLoadedMetadata);
          video.addEventListener('error', onError);
        });
      }
    } catch (err) {
      console.error('üìπ Camera Error:', err);
      let errorMsg = 'Kh√¥ng th·ªÉ truy c·∫≠p camera';
      
      if (err instanceof Error) {
        const errorName = (err as any).name || '';
        
        if (errorName === 'NotAllowedError') {
          errorMsg = isMobile() ? 
            'üö´ Camera Permission Required\n\n' +
            'C√°c b∆∞·ªõc c·∫•p quy·ªÅn:\n' +
            '‚Ä¢ Chrome: Nh·∫•n bi·ªÉu t∆∞·ª£ng üîí trong thanh ƒë·ªãa ch·ªâ\n' +
            '‚Ä¢ Safari: Settings > Safari > Camera > Allow\n' +
            '‚Ä¢ Reload trang sau khi c·∫•p quy·ªÅn' :
            'üö´ Camera Permission Denied\n\n' +
            'Click the camera icon üì∑ in the address bar\n' +
            'and allow camera access.';
        } else if (errorName === 'NotFoundError') {
          errorMsg = 'üì∑ No Camera Found\n\n' +
            'Ki·ªÉm tra:\n' +
            '‚Ä¢ Camera c√≥ ƒë∆∞·ª£c k·∫øt n·ªëi kh√¥ng?\n' +
            '‚Ä¢ ƒê√≥ng apps kh√°c ƒëang d√πng camera\n' +
            '‚Ä¢ Th·ª≠ camera kh√°c n·∫øu c√≥';
        } else if (errorName === 'NotSupportedError') {
          errorMsg = 'üö´ Camera Not Supported\n\n' +
            (isMobile() ? 
              'Y√™u c·∫ßu:\n‚Ä¢ Chrome ho·∫∑c Safari m·ªõi nh·∫•t\n‚Ä¢ K·∫øt n·ªëi HTTPS\n‚Ä¢ Permissions ƒë·∫ßy ƒë·ªß' :
              'Requirements:\n‚Ä¢ Modern browser (Chrome/Firefox/Safari)\n‚Ä¢ HTTPS connection\n‚Ä¢ Camera permissions');
        } else if (errorName === 'NotReadableError') {
          errorMsg = 'üîí Camera In Use\n\n' +
            'Camera ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi:\n' +
            '‚Ä¢ Tab browser kh√°c\n' +
            '‚Ä¢ ·ª®ng d·ª•ng kh√°c (Zoom, Teams, etc.)\n' +
            '‚Ä¢ ƒê√≥ng ch√∫ng v√† th·ª≠ l·∫°i';
        } else if (errorName === 'SecurityError') {
          errorMsg = 'üîê Security Error\n\n' +
            'Y√™u c·∫ßu:\n' +
            '‚Ä¢ HTTPS connection (hi·ªán t·∫°i: ' + location.protocol + ')\n' +
            '‚Ä¢ Proper camera permissions\n' +
            '‚Ä¢ Trusted domain';
        } else {
          errorMsg = '‚ùå' + err.message;
        }
      }
      
  // Avoid double notification: rely on onError callback for parent UI
  emitError(errorMsg);
    }
    finally {
      isStartingCameraRef.current = false;
    }
  };

  const stopCamera = () => {
    if (videoRef.current && videoRef.current.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach(track => track.stop());
      videoRef.current.srcObject = null;
      setIsCameraActive(false);
    }
    stopAutoRecognition();
  };

  const setupCanvas = () => {
    if (videoRef.current && canvasRef.current && overlayCanvasRef.current) {
      const video = videoRef.current;
      const canvas = canvasRef.current;
      const overlayCanvas = overlayCanvasRef.current;
      
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      overlayCanvas.width = video.videoWidth;
      overlayCanvas.height = video.videoHeight;
    }
  };

  const startAutoRecognition = () => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
    }
    
    // Use longer interval for mobile to improve performance
    const interval = isMobile() ? Math.max(recognizeInterval * 2, 3000) : recognizeInterval;
    // console.log('üîÑ Starting auto recognition with interval:', interval, 'ms for', isMobile() ? 'mobile' : 'desktop');
    
    intervalRef.current = setInterval(() => {
      recognizeFromVideo();
    }, interval);
  };

  const stopAutoRecognition = () => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
      intervalRef.current = null;
    }
  };

  /**
   * V·∫Ω face guide overlay (h√¨nh oval) ƒë·ªÉ h∆∞·ªõng d·∫´n user
   */
  const drawFaceGuide = useCallback(() => {
    if (!overlayCanvasRef.current || !videoRef.current) return;

    const canvas = overlayCanvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Calculate guide position (center of video)
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;
    
    // Guide size (oval shape for face)
    const guideWidth = canvas.width * 0.5;  // 50% of video width
    const guideHeight = canvas.height * 0.65; // 65% of video height

    // Draw semi-transparent overlay
    ctx.fillStyle = 'rgba(0, 0, 0, 0.5)';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    // Clear the guide area (create "hole" in overlay)
    ctx.save();
    ctx.globalCompositeOperation = 'destination-out';
    ctx.beginPath();
    ctx.ellipse(centerX, centerY, guideWidth / 2, guideHeight / 2, 0, 0, Math.PI * 2);
    ctx.fill();
    ctx.restore();

    // Draw guide border
    ctx.strokeStyle = isFaceAligned ? '#00ff00' : '#ffffff';
    ctx.lineWidth = 3;
    ctx.setLineDash(isFaceAligned ? [] : [10, 5]); // Solid when aligned, dashed when not
    ctx.beginPath();
    ctx.ellipse(centerX, centerY, guideWidth / 2, guideHeight / 2, 0, 0, Math.PI * 2);
    ctx.stroke();
    ctx.setLineDash([]); // Reset dash

    // Draw instruction text
    ctx.font = isMobile() ? '14px Arial' : '16px Arial';
    ctx.fillStyle = '#ffffff';
    ctx.textAlign = 'center';
    ctx.shadowColor = 'rgba(0, 0, 0, 0.8)';
    ctx.shadowBlur = 4;
    
    const instructionY = centerY + guideHeight / 2 + 40;
    if (isFaceAligned) {
      ctx.fillStyle = '#00ff00';
      ctx.fillText('‚úì Khu√¥n m·∫∑t ƒë√£ cƒÉn ch·ªânh!', centerX, instructionY);
    } else {
      ctx.fillText('ƒê·∫∑t khu√¥n m·∫∑t v√†o trong khung', centerX, instructionY);
    }
    
    ctx.shadowBlur = 0; // Reset shadow

    // Return guide boundaries for alignment check
    return {
      centerX,
      centerY,
      radiusX: guideWidth / 2,
      radiusY: guideHeight / 2
    };
  }, [isFaceAligned]);

  /**
   * T√≠nh ph·∫ßn trƒÉm di·ªán t√≠ch khu√¥n m·∫∑t n·∫±m trong oval
   * @returns Percentage of face area inside oval (0-100%)
   */
  const calculateFaceOverlapPercentage = (
    faceBox: { x: number; y: number; width: number; height: number },
    ovalCenterX: number,
    ovalCenterY: number,
    ovalRadiusX: number,
    ovalRadiusY: number
  ): number => {
    // Sample points trong face bounding box ƒë·ªÉ check overlap
    const sampleResolution = 10; // 10x10 grid = 100 sample points
    let pointsInside = 0;
    let totalPoints = 0;

    const stepX = faceBox.width / sampleResolution;
    const stepY = faceBox.height / sampleResolution;

    for (let i = 0; i < sampleResolution; i++) {
      for (let j = 0; j < sampleResolution; j++) {
        const pointX = faceBox.x + (i + 0.5) * stepX;
        const pointY = faceBox.y + (j + 0.5) * stepY;

        // Check if point is inside ellipse: (x-cx)¬≤/rx¬≤ + (y-cy)¬≤/ry¬≤ <= 1
        const dx = (pointX - ovalCenterX) / ovalRadiusX;
        const dy = (pointY - ovalCenterY) / ovalRadiusY;
        
        if (dx * dx + dy * dy <= 1) {
          pointsInside++;
        }
        totalPoints++;
      }
    }

    return (pointsInside / totalPoints) * 100;
  };

  /**
   * Ki·ªÉm tra xem khu√¥n m·∫∑t c√≥ n·∫±m trong v√πng guide kh√¥ng
   * ‚ú® Y√äU C·∫¶U: √çt nh·∫•t 80% khu√¥n m·∫∑t ph·∫£i n·∫±m trong oval
   */
  const checkFaceAlignment = useCallback(async () => {
    if (!videoRef.current || !overlayCanvasRef.current || !isModelLoaded) {
      return false;
    }

    try {
      // Detect face without full recognition
      const detections = await faceRecognizeService.detectFace(videoRef.current);
      
      if (detections.length === 0) {
        setIsFaceAligned(false);
        console.log('‚ùå No face detected');
        return false;
      }

      // Get guide boundaries
      const canvas = overlayCanvasRef.current;
      const centerX = canvas.width / 2;
      const centerY = canvas.height / 2;
      const guideRadiusX = canvas.width * 0.25;
      const guideRadiusY = canvas.height * 0.325;

      // Check if face is within guide area
      const detection = detections[0]; // Check first face only
      const box = detection.detection.box;

      // ‚ú® NEW: T√≠nh ph·∫ßn trƒÉm khu√¥n m·∫∑t trong oval
      const overlapPercentage = calculateFaceOverlapPercentage(
        box,
        centerX,
        centerY,
        guideRadiusX,
        guideRadiusY
      );

      console.log(`üìä Face overlap: ${overlapPercentage.toFixed(1)}% (minimum required: 80%)`);

      // ‚ú® Y√™u c·∫ßu √≠t nh·∫•t 80% khu√¥n m·∫∑t n·∫±m trong oval
      const MINIMUM_OVERLAP_PERCENTAGE = 80;
      const isOverlapOk = overlapPercentage >= MINIMUM_OVERLAP_PERCENTAGE;

      // Check if face size is appropriate (not too small or too large)
      const faceArea = box.width * box.height;
      const videoArea = canvas.width * canvas.height;
      const faceRatio = faceArea / videoArea;
      const isSizeOk = faceRatio >= 0.08 && faceRatio <= 0.5; // 8% to 50% of video

      const aligned = isOverlapOk && isSizeOk;
      
      if (!aligned) {
        if (!isOverlapOk) {
          console.log(`‚ö†Ô∏è Face alignment failed: Only ${overlapPercentage.toFixed(1)}% of face is inside oval (need ${MINIMUM_OVERLAP_PERCENTAGE}%)`);
        }
        if (!isSizeOk) {
          console.log(`‚ö†Ô∏è Face size check failed: Face ratio ${(faceRatio * 100).toFixed(1)}% (acceptable: 8-50%)`);
        }
      } else {
        console.log(`‚úÖ Face aligned! Overlap: ${overlapPercentage.toFixed(1)}%, Size: ${(faceRatio * 100).toFixed(1)}%`);
      }

      setIsFaceAligned(aligned);
      
      return aligned;
    } catch (err) {
      console.warn('Face alignment check failed:', err);
      setIsFaceAligned(false);
      return false;
    }
  }, [isModelLoaded]);

  /**
   * Animation loop ƒë·ªÉ v·∫Ω guide v√† check alignment
   */
  useEffect(() => {
    if (!isCameraActive || !isModelLoaded) return;

    let animationFrameId: number;
    let lastAlignmentCheck = 0;
    const ALIGNMENT_CHECK_INTERVAL = 500; // Check alignment every 500ms

    const animate = async (timestamp: number) => {
      // Draw guide overlay
      drawFaceGuide();

      // Check alignment periodically (not every frame for performance)
      if (timestamp - lastAlignmentCheck >= ALIGNMENT_CHECK_INTERVAL) {
        await checkFaceAlignment();
        lastAlignmentCheck = timestamp;
      }

      animationFrameId = requestAnimationFrame(animate);
    };

    animationFrameId = requestAnimationFrame(animate);

    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [isCameraActive, isModelLoaded, drawFaceGuide, checkFaceAlignment]);

  const recognizeFromVideo = useCallback(async () => {
    if (!videoRef.current || !overlayCanvasRef.current || !isModelLoaded || isRecognizing) {
      return;
    }

    // ‚ú® Y√äU C·∫¶U 1: CHECK alignment tr·ª±c ti·∫øp (kh√¥ng d√πng state ƒë·ªÉ tr√°nh stale data)
    const isCurrentlyAligned = await checkFaceAlignment();
    
    if (!isCurrentlyAligned) {
      console.log('üö´ FACE RECOGNITION SKIPPED: Face not aligned (need 80% inside oval)');
      console.log('   ‚Üí Recognition will NOT run until face is properly aligned');
      console.log('   ‚Üí Current state: isFaceAligned =', isFaceAligned, '(may be stale)');
      return;
    }

    // ‚úÖ Face ƒë√£ aligned, b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán
    console.log('üéØ FACE RECOGNITION STARTING: Face is aligned!');

    try {
      setIsRecognizing(true);
      setError('');
      
      const result = await faceRecognizeService.recognizeFace(videoRef.current);
      const results = [result]; // Wrap single result in array for compatibility
      
      console.log('‚úÖ FACE RECOGNITION COMPLETED:', results);
      
      // V·∫Ω k·∫øt qu·∫£ l√™n overlay canvas
      const overlayCanvas = overlayCanvasRef.current;
      overlayCanvas.width = videoRef.current.videoWidth;
      overlayCanvas.height = videoRef.current.videoHeight;
      
      faceRecognizeService.drawRecognitionResults(overlayCanvas, results);
      
      setLastResults(results);
      onRecognitionResult?.(results);
      
    } catch (err) {
  const errorMsg = 'L·ªói khi nh·∫≠n d·∫°ng: ' + (err as Error).message;
  emitError(errorMsg);
  console.error('‚ùå FACE RECOGNITION ERROR:', err);
    } finally {
      setIsRecognizing(false);
      console.log('üèÅ FACE RECOGNITION FINISHED');
    }
  }, [isModelLoaded, isRecognizing, isFaceAligned, checkFaceAlignment, onRecognitionResult, emitError]);

  // Test camera function for debugging
  const testCamera = async () => {
    // console.log('üîß Testing camera support...');
    setError(''); // Clear previous errors
    
    try {
      const cameraCheck = await checkCameraSupport();
      
      // console.log('üìπ Camera Check Result:', cameraCheck);
      
      let message = `üìπ Camera Test Results:\n\n`;
      message += `‚úÖ Supported: ${cameraCheck.supported ? 'YES' : 'NO'}\n`;
      message += `üìã Details: ${cameraCheck.details}\n\n`;
      
      if (cameraCheck.cameras.length > 0) {
        message += `ÔøΩ Available Cameras (${cameraCheck.cameras.length}):\n`;
        cameraCheck.cameras.forEach((camera, index) => {
          message += `${index + 1}. ${camera.label || 'Unknown Camera'}\n`;
        });
      } else {
        message += `üì∑ No cameras detected\n`;
      }
      
      message += `\nüåê Environment:\n`;
      message += `‚Ä¢ Protocol: ${location.protocol}\n`;
      message += `‚Ä¢ Host: ${location.hostname}\n`;
      message += `‚Ä¢ User Agent: ${navigator.userAgent.slice(0, 50)}...\n`;
      message += `‚Ä¢ Mobile: ${isMobile() ? 'YES' : 'NO'}`;
      
      notify.push('Camera test complete ‚Äì check console for details', cameraCheck.supported ? 'success' : 'error');
      
      // Also set error message if camera not supported
      if (!cameraCheck.supported) {
        setError(`‚ùå Camera Test Failed: ${cameraCheck.details}`);
      } else {
        setError(`‚úÖ Camera Test Passed: ${cameraCheck.details}`);
      }
      
    } catch (error) {
      console.error('üîß Camera test failed:', error);
      const errorMsg = `Camera test failed: ${(error as Error).message}`;
      emitError(errorMsg);
    }
  };

  const captureAndRegister = async () => {
    if (!videoRef.current || !isModelLoaded) return;

    const personName = prompt('Nh·∫≠p t√™n ng∆∞·ªùi c·∫ßn ƒëƒÉng k√Ω:');
    if (!personName) return;

    const personId = Date.now().toString();

    try {
      setError('');
      await faceRecognizeService.registerFace(videoRef.current, personId, personName);
      faceRecognizeService.saveFacesToStorage();
      notify.push(`ƒê√£ ƒëƒÉng k√Ω th√†nh c√¥ng khu√¥n m·∫∑t cho ${personName}`, 'success');
    } catch (err) {
      const errorMsg = 'L·ªói khi ƒëƒÉng k√Ω: ' + (err as Error).message;
      emitError(errorMsg);
      console.error(err);
      // Parent will surface error; avoid duplicate notification
    }
  };

  const captureImage = () => {
    if (!videoRef.current || !canvasRef.current) return;
    
    const canvas = canvasRef.current;
    const video = videoRef.current;
    
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    
    const ctx = canvas.getContext('2d');
    if (ctx) {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    }
  };

  // Registered faces are now managed in backend database

  return (
    <div className="face-recognition">
      {/* Status Bar */}
      <div className="status-bar">
        <div className="status-indicators">
          <div className={`status-indicator ${loading ? 'loading' : isModelLoaded ? 'ready' : 'error'}`}>
            <span className="status-icon">
              {loading ? '‚è≥' : isModelLoaded ? '‚úÖ' : '‚ùå'}
            </span>
            <span className="status-text">
              {loading ? 'ƒêang t·∫£i...' : isModelLoaded ? 'AI nh·∫≠n di·ªán khu√¥n m·∫∑t' : 'AI ch∆∞a s·∫µn s√†ng'}
            </span>
          </div>
          
          <div className={`status-indicator ${isCameraActive ? 'active' : 'inactive'}`}>
            <span className="status-icon">üìπ</span>
            <span className="status-text">
              Camera nh·∫≠n di·ªán khu√¥n m·∫∑t: {isCameraActive ? 'Ho·∫°t ƒë·ªông' : 'T·∫Øt'}
            </span>
          </div>

          <div className={`status-indicator ${isRecognizing ? 'active' : 'inactive'}`}>
            <span className="status-icon">üîç</span>
            <span className="status-text">
              GPS th√¥ng minh
            </span>
          </div>
        </div>
      </div>

      {/* Error Display - Hidden */}
      {false && error && (
        <div className="error-message">
          <span className="error-icon">‚ö†Ô∏è</span>
          <span className="error-text" style={{ whiteSpace: 'pre-line' }}>{error}</span>
        </div>
      )}

      {/* HTTPS Warning */}
      {location.protocol !== 'https:' && location.hostname !== 'localhost' && location.hostname !== '127.0.0.1' && (
        <div className="warning-message">
          <span className="warning-icon">üîí</span>
          <span className="warning-text">
            ‚ö†Ô∏è HTTPS Required: Camera needs HTTPS to work. 
            Current: {location.protocol}//{location.hostname}
            {location.hostname.includes('192.168') && ' (Try using HTTPS or localhost instead)'}
          </span>
        </div>
      )}

      {/* Camera View */}
      <div className="camera-container">
        <div className="video-wrapper">
          <video
            ref={videoRef}
            className="video-stream"
            muted
            playsInline
            style={{ display: isCameraActive ? 'block' : 'none' }}
          />
          
          {/* Overlay Canvas for face detection */}
          <canvas
            ref={overlayCanvasRef}
            className="overlay-canvas"
            style={{ display: isCameraActive ? 'block' : 'none' }}
          />
          
          {/* Hidden canvas for image capture */}
          <canvas
            ref={canvasRef}
            className="capture-canvas"
            style={{ display: 'none' }}
          />

          {/* Camera Placeholder */}
          {!isCameraActive && (
            <div className="camera-placeholder">
              <div className="placeholder-icon">üì∑</div>
              <div className="placeholder-text">Camera ch∆∞a kh·ªüi ƒë·ªông</div>
            </div>
          )}
        </div>
      </div>

      {/* Camera Control */}
      {!isCameraActive && (
        <div className="camera-control">
          <button 
            className="control-btn primary"
            onClick={startCamera}
            disabled={!isModelLoaded}
          >
            <span className="btn-icon">üìπ</span>
            B·∫≠t Camera
          </button>
        </div>
      )}

      {/* Controls - Hidden */}
      {false && (
      <div className="controls">
        <div className="control-group">
          <button 
            className="control-btn primary"
            onClick={startCamera}
            disabled={!isModelLoaded || isCameraActive}
          >
            <span className="btn-icon">üìπ</span>
            B·∫≠t Camera
          </button>

          <button 
            className="control-btn secondary"
            onClick={stopCamera}
            disabled={!isCameraActive}
          >
            <span className="btn-icon">‚èπÔ∏è</span>
            T·∫Øt Camera
          </button>

          <button 
            className="control-btn debug"
            onClick={testCamera}
            disabled={loading}
            title="Test camera support and permissions"
          >
            <span className="btn-icon">üîß</span>
            Test Camera
          </button>
        </div>

        <div className="control-group">
          <button 
            className="control-btn success"
            onClick={recognizeFromVideo}
            disabled={!isModelLoaded || !isCameraActive || isRecognizing}
          >
            <span className="btn-icon">üîç</span>
            {isRecognizing ? 'ƒêang nh·∫≠n d·∫°ng...' : 'Nh·∫≠n d·∫°ng'}
          </button>

          <button 
            className="control-btn info"
            onClick={captureAndRegister}
            disabled={!isModelLoaded || !isCameraActive}
          >
            <span className="btn-icon">‚ûï</span>
            ƒêƒÉng k√Ω khu√¥n m·∫∑t
          </button>

          <button 
            className="control-btn warning"
            onClick={captureImage}
            disabled={!isCameraActive}
          >
            <span className="btn-icon">üì∏</span>
            Ch·ª•p ·∫£nh
          </button>
        </div>
      </div>
      )}

      {/* Recognition Results */}
      {lastResults.length > 0 && (
        <div className="results-panel">
          <h3 className="results-title">K·∫øt qu·∫£ nh·∫≠n d·∫°ng:</h3>
          <div className="results-list">
            {lastResults.map((result, index) => (
              <div 
                key={index} 
                className={`result-item ${result.isMatch ? 'match' : 'no-match'}`}
              >
                <div className="result-avatar">
                  {result.isMatch ? '‚úÖ' : '‚ùì'}
                </div>
                <div className="result-info">
                  <div className="result-name">
                    {result.isMatch && result.person ? result.person.name : 'Kh√¥ng x√°c ƒë·ªãnh'}
                  </div>
                  <div className="result-confidence">
                    ƒê·ªô tin c·∫≠y: {result.confidence}%
                  </div>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* Registered Faces List - Now managed in backend database */}
      {/* Panel removed as faces are managed centrally in backend */}

      {/* Camera Requirements Modal */}
      {showRequirements && (
        <CameraRequirements onClose={() => setShowRequirements(false)} />
      )}
    </div>
  );
});

FaceRecognition.displayName = 'FaceRecognition';

export default FaceRecognition;
